{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Hackathon mobilités_logo simple.jpg\" alt=\"Logo Hackathon 2025\" width=\"400\"/>\n",
    "\n",
    "## Snippets de code \n",
    "\n",
    "Ces snippets de code vont vous permettre de gagner du temps dans la prise en main des ressources à disposition et de l'écosystème data d'île-de-France Mobilités. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire\n",
    "\n",
    "- [Appel d'API PRIM — Instanciation API](#appel-dapi-prim)\n",
    "  - [Appel d'API PRIM — Exemple de calcul d'itinéraire](#exemple-de-demande-de-calcul-ditinéraire)\n",
    "  - [Appel d'API PRIM — Passage du token et endpoint](#passage-du-token-et-appel-dun-endpoint)\n",
    "  - [Nomenclature pour les appels API](#nomenclature-pour-les-appels-api)\n",
    "    - [Code ligne vers identifiant SIRI](#code-ligne-vers-identifiant-de-ligne-siri)\n",
    "    - [Code arrêt vers identifiant d'arrêt SIRI](#code-arrêt-vers-identifiant--darrêt-siri)\n",
    "- [Onyxia — Connexion au stockage](#connexion-au-stockage)\n",
    "  - [Lecture S3](#lecture-dun-fichier-depuis-lespace-de-stockage-partagé-vers-une-dataframe-pandas)\n",
    "  - [Ecriture S3](#ecriture-dun-fichier-depuis-une-dataframe-pandas-vers-lespace-de-stockage-partagé)\n",
    "- [Utilisation de modèles ouverts sur Hugging Face en local](#utilisation-de-modèles-ouverts-sur-hugging-face-en-local)\n",
    "\n",
    "*Cliquez sur un titre (si votre visualiseur de notebook supporte les ancres) pour accéder à la section.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appel d'API PRIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/api_prim.png\" alt=\"Token authentification PRIM\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Informations API\n",
    "API_BASE = \"https://prim.iledefrance-mobilites.fr/marketplace/\"\n",
    "API_KEY = \"your-api-key\"  # remplacer par votre clé\n",
    "HEADERS = {\"Accept\": \"application/json\", \"apikey\": API_KEY}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple de demande de calcul d'itinéraire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = API_BASE + \"v2/navitia/journeys\"\n",
    "\n",
    "# Coordonnées (lon, lat) — des chaînes conviennent pour le tutoriel\n",
    "ORIGIN_LON = \"2.33792\"\n",
    "ORIGIN_LAT = \"48.85827\"\n",
    "DEST_LON = \"2.3588523\"\n",
    "DEST_LAT = \"48.9271087\"\n",
    "\n",
    "# Date/heure pour le trajet (format : YYYYMMDDTHHMMSS)\n",
    "TRIP_DATETIME = \"20241121T073000\"\n",
    "\n",
    "# Construire l'URL (Navitia attend lon;lat encodé en lon%3B%20lat)\n",
    "FROM_PARAM = f\"{ORIGIN_LON}%3B%20{ORIGIN_LAT}\"\n",
    "TO_PARAM = f\"{DEST_LON}%3B%20{DEST_LAT}\"\n",
    "URL = f\"{API_URL}?from={FROM_PARAM}&to={TO_PARAM}&datetime={TRIP_DATETIME}\"\n",
    "\n",
    "# Afficher l'URL pour que le lecteur voie comment elle est construite\n",
    "print(\"Aperçu de l'URL Navitia :\")\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécuter la requête inline (style tutoriel simple)\n",
    "try:\n",
    "    resp = requests.get(URL, headers=HEADERS)\n",
    "    print(\"Statut HTTP :\", resp.status_code)\n",
    "\n",
    "    if resp.status_code == 200:\n",
    "        data = resp.json()\n",
    "        # Aplatir le JSON de premier niveau pour inspection\n",
    "        df = pd.json_normalize(data)\n",
    "        print(\"Clés de premier niveau :\", list(data.keys()))\n",
    "\n",
    "        # Si des 'journeys' sont présents, inspecter le premier\n",
    "        if isinstance(data, dict) and data.get(\"journeys\"):\n",
    "            print(\"Premier trajet (aplatit) :\")\n",
    "            display(pd.json_normalize(data[\"journeys\"][0]))\n",
    "        else:\n",
    "            print(\"Aucun trajet ('journeys') retourné dans la réponse.\")\n",
    "    else:\n",
    "        print(\"Réponse non-200, corps (400 premiers caractères) :\")\n",
    "        print(resp.text[:400])\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"La requête a échoué :\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passage du token et appel d'un endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_LIGNE = \"C01742\"  # Exemple : RER A\n",
    "API_URL = f\"{API_BASE}general-message?LineRef=STIF%3ALine%3A%3A{ID_LIGNE}%3A\"\n",
    "\n",
    "# Affichage rapide pour vérification (utile en mode tutoriel)\n",
    "print(\"Requête vers :\", API_URL)\n",
    "\n",
    "# --- Requête inline et traitement minimal ---\n",
    "try:\n",
    "    response = requests.get(API_URL, headers=HEADERS)\n",
    "    print(\"Statut HTTP :\", response.status_code)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parser le JSON et l'afficher (ou l'extraire selon le besoin)\n",
    "        json_data = response.json()\n",
    "        print(\"Réponse JSON (extrait) :\")\n",
    "        # Affiche la structure JSON (ou un extrait) pour inspection\n",
    "        print(json.dumps(json_data, indent=2, ensure_ascii=False)[:1000])\n",
    "    else:\n",
    "        print(\"Échec de la requête HTTP. Statut :\", response.status_code)\n",
    "        print(\"Réponse (début) :\", response.text[:400])\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Une erreur s'est produite lors de l'appel HTTP :\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nomenclature pour les appels API\n",
    "##### Code ligne vers identifiant de ligne SIRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de l'id_ligne du référentiel des lignes en id compatible avec les API\n",
    "# /!\\ les \"deux points\" finaux sont indispensables\n",
    "\n",
    "code_ligne_idfm = \"C01742\"  # RER A\n",
    "id_ligne_idfm = \"STIF:Line::{id_ligne_idfm}:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code arrêt vers identifiant  d'arrêt SIRI\n",
    "_Note : les identifiant d'arrêts à prendre en compte sont en général les id de zones d'arrêt._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de ZdAId du référentiel des arrêts en id compatible avec les API\n",
    "# /!\\ les \"deux points\" finaux sont indispensables\n",
    "\n",
    "code_zone_arret_idfm = \"42135\"  # Les Dix Arpents\n",
    "id_arret_idfm = \"STIF:monomodalStopPlace::{code_zone_arret_idfm}:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onyxia\n",
    "#### Connexion au stockage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/acces_s3_onyxia.png\" alt=\"Accès S3 Onyxia\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Remplacer par vos propres informations d'identification et paramètres\n",
    "ACCESS_KEY = \"your-access-key\"\n",
    "SECRET_KEY = \"your-secret-key\"\n",
    "SESSION_TOKEN = \"your-session-token\"\n",
    "REGION = \"your-region\"\n",
    "ENDPOINT_URL = \"your-endpoint-url\"\n",
    "\n",
    "BUCKET = \"dlb-hackathon\"\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"https://\" + ENDPOINT_URL,\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    "    aws_session_token=SESSION_TOKEN,\n",
    "    region_name=REGION,\n",
    ")\n",
    "\n",
    "my_bucket = s3.Bucket(BUCKET)\n",
    "for my_bucket_object in my_bucket.objects.all():\n",
    "    print(my_bucket_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture d'un fichier depuis l'espace de stockage partagé vers une dataframe pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_KEY_S3 = \"/datasets-diffusion/ascenseurs_historique_etat/RELEVES_ETATS_ASCENSEURS_SNCF_RATP_2021-2024.csv\"\n",
    "\n",
    "response = s3.get_object(Bucket=BUCKET, Key=FILE_KEY_S3)\n",
    "status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "\n",
    "if status == 200:\n",
    "    df = pd.read_csv(response.get(\"Body\"))\n",
    "    print(\"Aperçu des données importées :\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Erreur lors de l'importation des données. Statut HTTP: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecriture d'un fichier depuis une dataframe pandas vers l'espace de stockage partagé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_KEY_S3 = \"tests_io_onyxia/books.csv\"\n",
    "books_df = pd.DataFrame(\n",
    "    data={\"Title\": [\"Book I\", \"Book II\", \"Book III\"], \"Price\": [56.6, 59.87, 74.54]},\n",
    "    columns=[\"Title\", \"Price\"],\n",
    ")\n",
    "\n",
    "with io.StringIO() as csv_buffer:\n",
    "    books_df.to_csv(csv_buffer, index=False)\n",
    "    response = s3.put_object(Bucket=BUCKET, Key=FILE_KEY_S3, Body=csv_buffer.getvalue())\n",
    "\n",
    "    status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "    if status == 200:\n",
    "        print(\"Fichier écrit avec succès dans l'espace de stockage partagé.\")\n",
    "    else:\n",
    "        print(f\"Erreur lors de l'écriture du fichier. Statut HTTP: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de modèles ouverts sur Hugging Face en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Cette instruction minimale permet de sélectionner le modèle et son niveau de compression, le téléchargement le paramétrage et la mise en mémoire (CPU), sont automatiques :\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"bartowski/gemma-2-2b-it-GGUF\",  # Plus gros dépôt de LLM libres de Hugging face : https://huggingface.co/bartowski\n",
    "    filename=\"gemma-2-2b-it-Q6_K_L.gguf\",  # Attention a prendre des modèles de taille <= 6Go pour des performances raisonnables, pas de garantie de fonctionnement au delà\n",
    "    n_ctx=4096,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Une fois le LLM chargé (environ une minute par Go), il peut être appelé, via une fonction *completion, ici pour un chatbot :\n",
    "llm_response = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"###SYSTEM : You are the Capital assistant. I give you a country, you give me the capital and try to retrieve the country iso code. ### FORMAT : Capital=<name of the Capital> CODE=<ISO CODE 2 CHARS>\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"OK, I understand. If you say France, i say Capital=Paris CODE=FR\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Germany\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# La réponse du LLM est pleine de métadonnées, mais le message texte peut être extrait de cette manière simple :\n",
    "print(llm_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
